---
title: "Question 3"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Thoughts about the Data

There are issues with the data concering compensation beyond the abundance of NA values (which can be removed for our purposes).

There are many entries that are 0 or a very low value (a couple thousand). There is no obvious way to interpret this, particularly the 0's. The appearance of really low values might suggest that some of the respondents are not in full time employment as data scientists. Perhaps some respondents are consultants, contractors, work part time / remotely, or even do it as a side gig. If this is the case, it could seriously interfere with any analysis of differences in compensation.

It might be worthwhile to look into dichotomizing the compensation data, in other words find somewhere to split it so that we can look at just the compensations which could be for full time employment, and perhaps separately look at the lower compensations.

## Preliminary Findings
```{r}
d0 <- read.csv("../Data/DataScienceData.csv")
```
These are all the present responses for level of education.
```{r}
d <- data.frame(d0$FormalEducation, d0$CompensationYearUSD)
d <- na.omit(d)
unique(d$d0.FormalEducation)
```

Here is plot of compensation in USD overall
```{r}
hist(d$d0.CompensationYearUSD)
max(d$d0.CompensationYearUSD)
mean(d$d0.CompensationYearUSD)
mean(d$d0.CompensationYearUSD[d$d0.FormalEducation=="Bachelor's degree"])
```
The highest value is 28 Billion and mean is 6 Million, so there is definitely some entry error or plain out junk data. It seems reasonable to remove outliers.

Below is data capped at 1 million USD.
```{r}
d <- d[d$d0.CompensationYearUSD < 500000,]
d <- d[d$d0.CompensationYearUSD > 20000,]
hist(d$d0.CompensationYearUSD)
```

```{r}
mean(d$d0.CompensationYearUSD)
sd(d$d0.CompensationYearUSD)
mean(d$d0.CompensationYearUSD[d$d0.FormalEducation=="Bachelor's degree"])
```
These numbers seem much more familiar and reasonable, except the standard deviation is almost equal to the mean, which is unusual. This is also being affected by the really low values that don't seem to correspond to full time employment. 

```{r}
unique(d$d0.FormalEducation)

"bachelor's"
bach = d[d$d0.FormalEducation=="Bachelor's degree",]
nrow(bach)
m_bachelor <- mean(bach$d0.CompensationYearUSD)
sd(bach$d0.CompensationYearUSD)

"master's"
mas = d[d$d0.FormalEducation=="Master's degree",]
nrow(mas)
m_master <- mean(mas$d0.CompensationYearUSD)
sd(mas$d0.CompensationYearUSD)

"doctorate"
doc = d[d$d0.FormalEducation=="Doctoral degree",]
nrow(doc)
m_doctor <- mean(doc$d0.CompensationYearUSD)
sd(doc$d0.CompensationYearUSD)

"professional"
prof = d[d$d0.FormalEducation=="Professional degree",]
nrow(prof)
m_professional <- mean(prof$d0.CompensationYearUSD)
sd(prof$d0.CompensationYearUSD)


groupmeans = c(m_bachelor, m_master, m_doctor, m_professional)
groupmeans
```
```{r}
d <- d[d$d0.FormalEducation != "I did not complete any formal education past high school",]
d <- d[d$d0.FormalEducation != "Some college/university study without earning a bachelor's degree",]
d <- d[d$d0.FormalEducation != "I prefer not to answer",]

```
The sample sizes lower dramatically beyond the three major categories of bachelor's, master's, and doctorate degrees. Might it be reasonable to only look at those three?


## **Question 3: Among professionals in the data science industry, does compensation differ significantly based on level of education?**

### *Analyzing the power of Welch t test,*

Power of multiple Welch t test to detect a difference of $10,000 in salary between any of three educational groups.
```{r}
set.seed(3)
n = 700
n2 = 1530
n3 = 800

m1 = 50000
m2 = 60000
m3 = 70000

s1 = 50000
s2 = 55000
s3 = 60000

reps=1000
pvalues=data.frame(p12=rep(NA,reps),p13=rep(NA,reps),p23=rep(NA,reps))
for(i in 1:reps){
  x1=rnorm(n,m1,s1)
  x2=rnorm(n2,m2,s2)
  x3=rnorm(n3,m3,s3)
  pvalues$p12[i]=t.test(x1,x2,var.equal=F)$p.value
  pvalues$p13[i]=t.test(x1,x3,var.equal=F)$p.value
  pvalues$p23[i]=t.test(x2,x3,var.equal=F)$p.value
}

# This creates a dataframe with a TRUE or FALSE value for each pairwise test indicating if it rejected
# as well as a column indicating if any one test rejected
reject = data.frame(pvalues < 0.05, any.rejection=apply(pvalues<0.05, 1, any))

# This calculates the mean TRUE entries in each column (proportion of rejections) and shows a given number of decimal places for the results
results = apply(reject,2,mean)
dec = 5
format(round(results, dec), nsmall=dec)
```
When simulating for the alternative hyothesis (difference of $10,000 between each of 3 groups), the test between the simulated groups with lowest and highest means will logically have the highest power. In the simulation, this test had a power of 1, meaning that the overall power for detecting a difference when each group is separated by 10,000 is 1. This is not too hard to believe given the very large sample sizes and properties of the available data.

### *Analyzing the power of ANOVA*
The large sample sizes allow us to overlook the assumption of normal distributions within the groups for ANOVA. The assumption of equal variances is not as clearly met, so with the acknowledgement that the present differences may be enough to invalidate the use of ANOVA, we report the results of the power analysis regardless.
```{r}
groupmeans
anovaP <- power.anova.test(groups = 4, 
between.var = var(groupmeans), within.var = 50000^2, 
power=NULL,sig.level=0.05,n=c(700, 1500, 800, 100))

anovaP
```

Like the multiple t - test, ANOVA would have a power of 1 given our sample size and the variances present in the data. Power for a sample size of 100 (the samller groups) is about 88.6%, but with the sample sizes of the three biggest groups it is 100%.
### *Analyzing the power of linear regression*



### *Test for significant difference between the different education groups (Bachelor, Mastersâ€™, PhD)*
```{r}
d$d0.FormalEducation <- ordered(d$d0.FormalEducation,
                         levels = c("Professional degree", "Bachelor's degree", "Master's degree", "Doctoral degree"))
```
```{r}
summary(aov(d$d0.CompensationYearUSD ~ d$d0.FormalEducation, data = d))
```
P-Value result from ANOVA: 1.79e-15

The null hypothesis is rejected, there is a significant difference between education level groups.

### *Visualizing the Distributions*
```{r}
ggplot(d) +
  ggtitle("Distributions of Salary per Education Group") +
  xlab("Salary in USD") +
  labs(fill= "Salary in USD", color="Salary in USD") +
  geom_density(aes(x=d$d0.CompensationYearUSD, fill=d$d0.FormalEducation, color=d$d0.FormalEducation), alpha=0.4)
```
Interestingly, it appears that besides PhD's, the difference in means for the other groups has more to do with the tail of the distribution than with a major difference between the bulk.
### *Test for linear relationship in compensation as an increase in education level*
```{r}
summary(lm(d$d0.CompensationYearUSD ~ factor(d$d0.FormalEducation), data=d))
```
P-Value result from linear regression: 1.786e-15
Coefficient: 16827
Each level of increase in education corresponds to about a $16,827 increase in salary. 

The relation between education level and salary is 
